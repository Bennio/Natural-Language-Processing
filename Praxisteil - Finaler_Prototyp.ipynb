{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose of this kernel\n",
    "\n",
    "- Kernel illustrates the final solution for the Quora Insincere Questions Classifiation Dataset\n",
    "- Kernel was run on GPU with Cuda/CuDNN to accelerate Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc # Garbage Collection to delete references and instances which are not needed anymore (Memory Management)\n",
    "import sys\n",
    "import time # To monitor execution time of different code sections\n",
    "\n",
    "# Preprocessing\n",
    "import seaborn as sns\n",
    "import re\n",
    "from re import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "lemmatizer = nltk.WordNetLemmatizer() # lemmatizer checks english word net\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras.layers import SimpleRNN, GRU, Bidirectional, LSTM,CuDNNLSTM, CuDNNGRU\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras import backend\n",
    "\n",
    "# Training\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Evaluation\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU on?  -  True\n",
      "Available GPUs:  /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# check status and availability of GPU\n",
    "print(\"GPU on?  - \", tf.test.is_gpu_available())\n",
    "print(\"Available GPUs: \", tf.test.gpu_device_name())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0 # test if Keras sees GPU, if not trigger an error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/quora-insincere-questions-classification/train.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/test.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/README.txt\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "# inspect available files in workspacce\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "* Hyperparameters are used to control the behaviour of the code in the Data Preparation and Model Training parts below\n",
    "* The Machine Learning Model for Quora is trained 10 epochs for evaluation purposes <b>(cf. chapter 9.2.2 in thesis)</b>\n",
    "* Since model does not show significant improvements from epoch 7 on, training process could be stopped here to reduce kernel runtime. However, because model performance (F1) is quite stable until epoch 10 and the epoch-hyperparameter could be left as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of samples to use within this script\n",
    "#total_train_samples = 30000 # used if script is executed in development mode (train with reduced sample size)\n",
    "#total_test_samples = 10000 # used if script is executed in development mode (test with reduced sample size)\n",
    "total_train_samples = 1306122 # use all samples in training set\n",
    "total_test_samples = 375806 # use all samples in test set\n",
    "\n",
    "# Data Preparation\n",
    "maxlen = 130 # 130 - covers about 75% of all bad questions completely, processing more characters did not lead to an increase in model performance\n",
    "max_words = 9999999 # dummy to use all words within word_index (=vocabulary derived from questions)\n",
    "\n",
    "# Training\n",
    "model_epochs = 10 # number of epochs the model is trained \n",
    "\n",
    "# Evaluation with Cross Validation\n",
    "\"\"\"\n",
    "State-of-the-Art to evaluate a model is Cross-validation with k = 5 or k = 10.\n",
    "However this would exceed the maximum allowed kernel runtime.\n",
    "Since results are quite stable across different k, it was decided to use k = 3 to evaluate model performnace.\n",
    "k = 3 poses a good tradeoff between runtime and meaningful evaluation\n",
    "\"\"\"\n",
    "kfolds = 3 # perform StratifiedShuffleSplit with k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "* 1 - This section contains the preprocessing function and corresponding mapping dictionaries\n",
    "* 2 - This section contains the my_tokenizer function\n",
    "* 3 - This sections contains the functions to create the embedding matrix\n",
    "* 4 - This section contains the execution of all data processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definition preprocessing function and mapping dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Preprocessing function\n",
    "\n",
    "* function replaces some special characters \n",
    "* function replaces numbers and year dates by a dummy (#). </br> The dummy is covered by the embeddings and can be used to tell the model that the token is about numbers or years.\n",
    "* function resolves word contractions\n",
    "* function performs normalization (spell correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x):\n",
    "    x = str(x)\n",
    "    x = re.sub('[’‘´`]', \"'\", x) \n",
    "    \n",
    "    # replaces one digit by #, two following digits by ## etc.\n",
    "    x = re.sub('[0-9]{5,}', '#####', str(x)) \n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    x = re.sub('[0-9]\\'[0-9]', 'feet inches', x) # e.g. 5'5 → feet inches\n",
    "    \n",
    "    for word in x.split():\n",
    "        if word.lower() in contraction_mapping.keys():\n",
    "            x = x.replace(word, contraction_mapping[word.lower()])\n",
    "        if word in correct_spell_dict.keys():\n",
    "            x = x.replace(word, correct_spell_dict[word])\n",
    "        if word in specials_mapping.keys():\n",
    "            x = x.replace(word, specials_mapping[word])\n",
    "        if word[0] in punct and len(word) != 1: # remove punctuation directly in front of word\n",
    "            x = x.replace(word[0], '') \n",
    "        \n",
    "    x = ' '.join(word_tokenize(x)) # separates puncutation from words\n",
    "               \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Mapping dictionaries\n",
    "\n",
    "* mapping dicts are used in above defined preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping to resolve word contractions (contraction = two words tightened to a new word with the same meaning)\n",
    "\"\"\"mapping from https://www.kaggle.com/noexittv/embeddings-keras-v04\"\"\"\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \n",
    "                       \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \n",
    "                       \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \n",
    "                       \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \n",
    "                       \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \n",
    "                       \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
    "                       \"I'm\": \"I am\",\"i'm\": \"i am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                       \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                       \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \n",
    "                       \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \n",
    "                       \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \n",
    "                       \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                       \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \n",
    "                       \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \n",
    "                       \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \n",
    "                       \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "                       \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \n",
    "                       \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
    "                       \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
    "                       \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                       \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \n",
    "                       \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
    "                       \"weren't\": \"were not\",\"what`s\": \"what is\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                       \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                       \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                       \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \n",
    "                       \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "                       \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "                       \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \n",
    "                       \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \n",
    "                       \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "\n",
    "# dict to perform some spell corrections\n",
    "\"\"\"reused from https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2 \"\"\"\n",
    "correct_spell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite',\n",
    "                    'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
    "                    'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization',\n",
    "                    'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n",
    "                    'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What',\n",
    "                    'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are',\n",
    "                    'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many',\n",
    "                    'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best',\n",
    "                    'howdoes': 'how does', 'mastrubation': 'masturbation',\n",
    "                    'mastrubate': 'masturbate', \"mastrubating\": 'masturbating',\n",
    "                    \"mcdonald's\":'mcdonalds',\n",
    "                    'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist',\n",
    "                    'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', \n",
    "                    'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what',\n",
    "                    'watsapp': 'whatsapp', 'demonitisation': 'demonetization',\n",
    "                    'demonitization': 'demonetization', 'demonetisation': 'demonetization',\n",
    "                    'pokémon': 'pokemon', 'quoras': 'quora', 'quorans': 'quora'}\n",
    "\n",
    "\n",
    "# remove some sepcial characters\n",
    "\"\"\"mapping from https://www.kaggle.com/noexittv/embeddings-keras-v04\"\"\"\n",
    "specials_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \n",
    "                 \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', \n",
    "                 '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', \n",
    "                 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '\\u200b': ' ',\n",
    "                 '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': '', 'ε−': ''}\n",
    "\n",
    "\n",
    "# custom punctuation marks that are removed. \n",
    "\"\"\"Important: \"#\" is not contained in punct, because this is the dummy for numbers of year dates  \"\"\" \n",
    "punct = \"/-?!.,$%\\()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&' + '\\''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definition my_tokenizer function\n",
    "\n",
    "* function translates the Quora question texts into integer sequences\n",
    "* function applies padding to the sequences. Integer sequences are padded to a length defined by the parameter \"maxlen\" (=130) \n",
    "* function creates a vocabulary out of the the question texts (=word_index). Vocabulary contains all tokens that are present within the questions\n",
    "* word_index is later used to create the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(texts):\n",
    "        tokenizer = Tokenizer() \n",
    "        tokenizer.fit_on_texts(texts) \n",
    "        sequences = tokenizer.texts_to_sequences(texts)\n",
    "        padded_seq = pad_sequences(sequences, maxlen=maxlen)  \n",
    "        word_index = tokenizer.word_index  \n",
    "        \n",
    "        return padded_seq, word_index, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Definition of functions to create the embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Define embeddings source path and define which embeddings to use\n",
    "\n",
    "* extensive experiments regarding which embeddings to use were performed\n",
    "* Single Embeddings:\n",
    "    * With the single Paragram embedding the Quora questions vocabulary could be covered the best (79.15% coverage) <b>(cf. chapter 9.1.2 in thesis)</b>\n",
    "    * GloVe (77.71%), Fasttext (71.89), GoogleNews (39.87%)\n",
    "* As discussed in chapter 3.4, meta-embeddings are a successful technique to further improve process of vectorization:\n",
    "    * \"Averaging\" of Glove+ Paragram and GloVe + Fasttext performed worse than \"Embedding Concatenation\"\n",
    "    * Final solution is the concatenation of Paragram and Fasttext embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings path\n",
    "_glove = '/kaggle/input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "_paragram =  '/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "_wiki_news = '/kaggle/input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "_google_news = '/kaggle/input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "# Use Paragram and Fasttext embedding\n",
    "embeddings = [\n",
    "              #{'name': 'glove', 'embeddings_path': _glove},\n",
    "              {'name': 'paragram', 'embeddings_path': _paragram},\n",
    "              {'name': 'fasttext', 'embeddings_path': _wiki_news}#,\n",
    "              #{'name': 'googlenews', 'embeddings_path': _google_news}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Definition of functions to load and analyse embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for lemmatization from http://textmining.wp.hs-hannover.de/Preprocessing.html\n",
    "\n",
    "def wntag(pttag):\n",
    "    if pttag in ['JJ', 'JJR', 'JJS']:\n",
    "        return wn.ADJ\n",
    "    elif pttag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "        return wn.NOUN\n",
    "    elif pttag in ['RB', 'RBR', 'RBS']:\n",
    "        return wn.ADV\n",
    "    elif pttag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "        return wn.VERB\n",
    "    return None\n",
    "\n",
    "def lemmatize(lemmatizer,word,pos):\n",
    "    if pos == None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embedding matrix\n",
    "embedding_matrices = {}\n",
    "words_in_embedding = {}\n",
    "def create_model_embedding_matrix(embeddings_name,word_index,max_words, embeddings_dict):   \n",
    "\n",
    "    \"\"\"\n",
    "    function parameters are:\n",
    "        * embeddings_name: name of embedding which is scaned\n",
    "        * word_index: vocabulary created by my_tokenizer function\n",
    "        * max_words: number of words within the word_index that shall be used to create the embedding\n",
    "           e.g. if max_words = 5 then for the TOP 5 most frequent occuring words within the questions an embedding is created\n",
    "        * embeddings_dict: embedding from which vectors shall be extracted e.g. Paragram Embedding\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding_dim = 300 # (vector size 300!)\n",
    "    embedding_matrix = np.zeros((max_words+1, embedding_dim)) # Creation of empty embedding matrix\n",
    "    unknown_words_list = []\n",
    "    num_known_words = 0  \n",
    "        \n",
    "    ps = PorterStemmer() # Creation of PorterStemmer Object\n",
    "    ps_counter = 0\n",
    "    lc = LancasterStemmer() # Creation of LancasterStemmer Object\n",
    "    lc_counter = 0\n",
    "    sb = SnowballStemmer(\"english\") # Creation of SnowballStemmer Object for the english language \n",
    "    sb_counter = 0\n",
    "    lemma_counter = 0\n",
    "\n",
    "    # Fill empty embedding_matrix with vecors from provided embedding\n",
    "    for word, i in word_index.items(): # run through word_index\n",
    "        \n",
    "        # section which is executed if glove, paragram oder fasttext embedding is used\n",
    "        if embeddings_name in ['glove', 'paragram', 'fasttext'] and i <= max_words:\n",
    "            \n",
    "            embedding_vector = embeddings_dict.get(word) # get vector for word from embedding \n",
    "            if embedding_vector is not None: # if an vector for the word was found within the embedidng\n",
    "                embedding_matrix[i] = embedding_vector # add vector to embedding vector at position i\n",
    "                num_known_words +=1 # counter for found words\n",
    "                continue # if embedding found - process next word\n",
    "            \n",
    "            # if no vector was found in the previous step, try below word transformation\n",
    "            word_c = word.lower() #lLowercase word\n",
    "            embedding_vector = embeddings_dict.get(word_c)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                num_known_words +=1\n",
    "                continue # if embedding found - process next word\n",
    "                \n",
    "            # if no vector was found in the previous step, try below word transformation \n",
    "            word_c = word.capitalize() # capitalize Word\n",
    "            embedding_vector = embeddings_dict.get(word_c)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                num_known_words +=1\n",
    "                continue # if embedding found - process next word\n",
    "            \n",
    "            # if no vector was found in the previous step, try below word transformation\n",
    "            word_c = word.upper() # uppercase all letters of word\n",
    "            embedding_vector = embeddings_dict.get(word_c)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                num_known_words +=1\n",
    "                continue # if embedding found - process next word\n",
    "              \n",
    "            # if no vector was found in the previous step, try below word transformation\n",
    "            word_c = ps.stem(word) # apply porter stemmer to word\n",
    "            embedding_vector = embeddings_dict.get(word_c)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                num_known_words +=1\n",
    "                ps_counter +=1\n",
    "                continue # if embedding found - process next word\n",
    "            \n",
    "            # if no vector was found in the previous step, try below word transformation\n",
    "            word_c = lc.stem(word) # apply lancaster stemmer to word\n",
    "            embedding_vector = embeddings_dict.get(word_c)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                num_known_words +=1\n",
    "                lc_counter +=1\n",
    "                continue # if embedding found - process next word\n",
    "                \n",
    "            # if no vector was found in the previous step, try below word transformation  \n",
    "            word_c = sb.stem(word) # apply snowball stemmer to word\n",
    "            embedding_vector = embeddings_dict.get(word_c)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                num_known_words +=1\n",
    "                sb_counter +=1\n",
    "                continue # if embedding found - process next word\n",
    "            \n",
    "            # Perform lemmatization if no embedding vector was found by previous word transformations\n",
    "            # This step is quite costly. For this reasion, lemmatization is the last step in the word transformation pipeline\n",
    "            word_c = lemmatize(lemmatizer,pos_tag([word])[0][0],wntag(pos_tag([word])[0][1])) \n",
    "            embedding_vector = embeddings_dict.get(word_c)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                num_known_words +=1\n",
    "                lemma_counter +=1\n",
    "                continue # if embedding found - process next word\n",
    "                \n",
    "            else:\n",
    "                unknown_words_list.append(word)\n",
    "        \n",
    "        # section which is executed if googlenews embedding is used\n",
    "        if embeddings_name == 'googlenews' and i <= max_words:\n",
    "            \n",
    "            try:\n",
    "                word_c = word\n",
    "                embedding_vector = embeddings_dict[word_c]  \n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1\n",
    "                    continue # if embedding found - process next word\n",
    "                \n",
    "                # if no vector was found in the previous step, try below word transformation\n",
    "                word_c = word.lower()\n",
    "                embedding_vector = embeddings_dict[word_c]  \n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1\n",
    "                    continue # if embedding found - process next word\n",
    "                    \n",
    "                # if no vector was found in the previous step, try below word transformation\n",
    "                word_c = word.capitalize()\n",
    "                embedding_vector = embeddings_dict[word_c]\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1 \n",
    "                    continue # if embedding found - process next word\n",
    "                \n",
    "                # if no vector was found in the previous step, try below word transformation\n",
    "                word_c = word.upper()\n",
    "                embedding_vector = embeddings_dict[word_c]   \n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1\n",
    "                    continue # if embedding found - process next word\n",
    "                 \n",
    "                # if no vector was found in the previous step, try below word transformation\n",
    "                word_c = ps.stem(word)\n",
    "                embedding_vector = embeddings_dict[word_c]  \n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1\n",
    "                    ps_counter +=1\n",
    "                    continue # if embedding found - process next word\n",
    "                    \n",
    "                # if no vector was found in the previous step, try below word transformation \n",
    "                word_c = lc.stem(word)\n",
    "                embedding_vector = embeddings_dict[word_c] \n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1\n",
    "                    lc_counter +=1\n",
    "                    continue # if embedding found - process next word\n",
    "                    \n",
    "                # if no vector was found in the previous step, try below word transformation\n",
    "                word_c = sb.stem(word)\n",
    "                embedding_vector = embeddings_dict[word_c] \n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1\n",
    "                    sb_counter +=1\n",
    "                    continue # if embedding found - process next word\n",
    "                   \n",
    "                # if no vector was found in the previous step, try below word transformation\n",
    "                word_c = lemmatize(lemmatizer,pos_tag([word])[0][0],wntag(pos_tag([word])[0][1]))\n",
    "                embedding_vector = embeddings_dict[word_c] \n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    num_known_words +=1\n",
    "                    lemma_counter +=1\n",
    "                    continue # if embedding found - process next word\n",
    "                    \n",
    "            except:\n",
    "                unknown_words_list.append(word)\n",
    "                \n",
    "    try: \n",
    "        words_in_embedding[embeddings_name] = list(embeddings_dict.keys())\n",
    "    except:\n",
    "        try:\n",
    "            words_in_embedding[embeddings_name] = list(embeddings_dict.wv.vocab)\n",
    "        except:\n",
    "            print(\"Error during generation of key list {}\".format(embeddings_name))\n",
    "            print(sys.exc_info()[0])\n",
    "    \n",
    "    # Print results\n",
    "    print('  Embeddings_matrix created')\n",
    "    print('  Shape embedding_matrix: {}'.format(embedding_matrix.shape))\n",
    "    print('  Found Embeddings for {:.2f}% of all words'\n",
    "          .format((num_known_words / max_words)*100)) # most important output: Informs about Embedding Coverage!\n",
    "    print(\"  num_known_words :\", num_known_words)\n",
    "    print(\"  num words in word_index: \", max_words)\n",
    "    print('  Unknown Words: {:.2f}%'.\n",
    "          format(((len(unknown_words_list)) / max_words)*100))\n",
    "    print(\"  Words found by PorterStemmer: {}\".format(ps_counter))\n",
    "    print(\"  Words found by LancasterStemmer: {}\".format(lc_counter))\n",
    "    print(\"  Words found by SnowballStemmer: {}\".format(sb_counter))\n",
    "    print(\"  Words found by Lemmatisation: {}\".format(lemma_counter))\n",
    "          \n",
    "    # Top 50 unknown words\n",
    "    print(\"  Top 50 unknown words:\\n {}\\n\".format(unknown_words_list[:50]))\n",
    "    \n",
    "    # Memory Management: Delete references and instances which are not needed anymore\n",
    "    del num_known_words, unknown_words_list,ps,lc,sb, ps_counter, lc_counter, sb_counter\n",
    "    del lemma_counter; gc.collect() # use garbage collection\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load + analyze Embeddings\n",
    "def load_and_analyse_Embeddings(embeddings_name, embeddings_path, max_words):\n",
    "    \n",
    "    \"\"\"\n",
    "    function loads embeddings from path in workspace (see section 3.1)\n",
    "    \n",
    "    function parameters are:\n",
    "        * embeddings_name: name of embedding which is scaned\n",
    "        * embeddings_path: source path where to load embedding from\n",
    "        * max_words: number of words within the word_index that shall be used to create the embedding\n",
    "           e.g. if max_words = 5 then for the TOP 5 most frequent occuring words within the questions an embedding is created\n",
    "    \"\"\"\n",
    "    \n",
    "    # if glove, paragram oder fasttext shall be loaded this section is executed\n",
    "    if embeddings_name in ['glove', 'paragram', 'fasttext']:  \n",
    "        embeddings_dict = {} # create empty embedding dictionary\n",
    "        embedding_file = open(embeddings_path, encoding =\"utf8\", errors = 'ignore') # load embedding from path\n",
    "\n",
    "        # Fill embedding dict with word: vector(coefs) pairs\n",
    "        for line in embedding_file:\n",
    "            line_values = line.split(' ') # read in values of respective line (= vector)\n",
    "            word = line_values[0] #  # first value in line represents the word\n",
    "            coefs = np.asarray(line_values[1:], dtype='float32') # all values represent vector\n",
    "            embeddings_dict[word] = coefs # add key(word), value(vector) pairs to dict\n",
    "\n",
    "        embedding_file.close() \n",
    "        \n",
    "        os.system('echo '+ embeddings_name + 'loaded')\n",
    "        print('  ',embeddings_name, 'loaded')\n",
    "        print('  {} word vectors within {} dict'.format(len(embeddings_dict),embeddings_name))\n",
    "        \n",
    "        # Use pre-trained embedding to create final embeddings matrix\n",
    "        embedding_matrix = create_model_embedding_matrix(embeddings_name,word_index,max_words, embeddings_dict)\n",
    "        del embeddings_dict, line_values,word,coefs\n",
    "        \n",
    "    # if googlenews shall be loaded this section is executed\n",
    "    if embeddings_name == 'googlenews':\n",
    "        embeddings_file = KeyedVectors.load_word2vec_format(embeddings_path, binary=True)\n",
    "        \n",
    "        os.system('echo '+ embeddings_name + 'loaded')\n",
    "        print('  ',embeddings_name, 'loaded')\n",
    "        \n",
    "        # Use pre-trained embedding to create final embeddings matrix\n",
    "        embedding_matrix = create_model_embedding_matrix(embeddings_name,word_index,max_words, embeddings_file)\n",
    "        del embeddings_file\n",
    "        \n",
    "    # MEMORY MANAGEMENT!\n",
    "    del embeddings_name, embeddings_path\n",
    "    gc.collect()\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Function to concatenate embeddings\n",
    "\n",
    "* function concatenates Paragram and Fasttext embedding to improve words representation\n",
    "* since each embedding represents a words through a 300-dimensional vector, the concatenation leads to 600-dimensional feature vector in the final embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_embeddings(conc_embedding, embedding_matrix):\n",
    "    \"\"\"\n",
    "    conc_embedding: \n",
    "    \"\"\"\n",
    "    \n",
    "    if conc_embedding is not None:\n",
    "        conc_embedding = np.concatenate((conc_embedding,embedding_matrix), axis = 1 )\n",
    "        print(\"Added embedding. New shape: {}\".format(conc_embedding.shape))\n",
    "    else:\n",
    "        conc_embedding = embedding_matrix\n",
    "        print(\"Added embedding. First shape: {}\".format(conc_embedding.shape))\n",
    "        \n",
    "    del embedding_matrix; gc.collect()\n",
    "    return conc_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Execution Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor execution time of different code sections\n",
    "runtime_dict = {}\n",
    "start_prep = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Load training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data from workspace\n",
    "train = pd.read_csv(\"/kaggle/input/quora-insincere-questions-classification/train.csv\")\n",
    "str_ = 'Train data loaded'\n",
    "os.system('echo '+str_)\n",
    "\n",
    "# Load test data from workspace\n",
    "test = pd.read_csv(\"/kaggle/input/quora-insincere-questions-classification/test.csv\")\n",
    "str_ = 'Test data loaded'\n",
    "os.system('echo '+str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape for this run:  1681928 3\n"
     ]
    }
   ],
   "source": [
    "train = train[:total_train_samples] # in test mode: use subsample of original data frame\n",
    "test = test[:total_test_samples] # in test mode: use subsample of original data frame\n",
    "\n",
    "# Concatenate both dataframes to cover maximum number of words in final embedding matrix\n",
    "df = pd.concat([train, test], axis = 0, sort = False, ignore_index = True) # do not sort non-concatenation axis \n",
    "\n",
    "num_samples,n = df.shape\n",
    "print(\"Shape for this run: \", num_samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (1306123, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  \\\n",
       "0  00002165364db923c7e6   \n",
       "1  000032939017120e6e44   \n",
       "2  0000412ca6e4628ce2cf   \n",
       "3  000042bf85aa498cd78e   \n",
       "4  0000455dfa3e01eae3af   \n",
       "\n",
       "                                                                       question_text  \\\n",
       "0           How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1  Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                          How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4      Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting part of dataframe which contains training data\n",
    "pd.set_option('display.max_colwidth', 1500) # inrease display column size\n",
    "print(\"Shape of training data: \", df.loc[:total_train_samples, :].shape)\n",
    "df.loc[:total_train_samples, :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test data:  (375806, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1306122</td>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arrogant when they get just a little bit of wealth and power?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306123</td>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineering and BMS college of engineering? Should I wait for the COMEDK result or am I supposed to apply before the result?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306124</td>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitioner?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306125</td>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306126</td>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1306122  0000163e3ea7c7a74cd7   \n",
       "1306123  00002bd4fb5d505b9161   \n",
       "1306124  00007756b4a147d2b0b3   \n",
       "1306125  000086e4b7e1c7146103   \n",
       "1306126  0000c4c3fbe8785a3090   \n",
       "\n",
       "                                                                                                                                                              question_text  \\\n",
       "1306122                                                               Why do so many women become so rude and arrogant when they get just a little bit of wealth and power?   \n",
       "1306123  When should I apply for RV college of engineering and BMS college of engineering? Should I wait for the COMEDK result or am I supposed to apply before the result?   \n",
       "1306124                                                                                                                  What is it really like to be a nurse practitioner?   \n",
       "1306125                                                                                                                                              Who are entrepreneurs?   \n",
       "1306126                                                                                                                    Is education really making good people nowadays?   \n",
       "\n",
       "         target  \n",
       "1306122     NaN  \n",
       "1306123     NaN  \n",
       "1306124     NaN  \n",
       "1306125     NaN  \n",
       "1306126     NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting part of dataframe which contains test data\n",
    "pd.set_option('display.max_colwidth', 1500) # inrease display column size\n",
    "print(\"Shape of test data: \",df.loc[total_train_samples:, :].shape)\n",
    "df.loc[total_train_samples:, :].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Apply preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing Function\n",
    "os.system('echo Applying preprocessing functions..')\n",
    "df[\"question_text\"] = df[\"question_text\"].fillna(\" \").apply(lambda x: preprocessing(x))\n",
    "os.system('echo prepocessing done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Extraction questions and target labels from data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape data tensor: (1681928,)\n",
      "Shape target tensor: (1681928,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, 'question_text'].values\n",
    "y = np.asarray(df.loc[:, 'target'].values) # Since Neural Networks are only able to perform transformations on tensors \n",
    "print('Shape data tensor:', X.shape) \n",
    "print('Shape target tensor:', y.shape) # 1D Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Apply my_tokenizer function\n",
    "\n",
    "* translates question text in interger sequences <b>(cf. chapter 8.2.2 in thesis)</b>\n",
    "* creates word index and tokenizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample padded sequence [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    9   46 6825 6951  155   57 5972   37    4\n",
      " 1123    6    1  187]\n",
      "\n",
      "Shape of padded_seq (1681928, 130)\n",
      "Number of words in word_index:  216315\n"
     ]
    }
   ],
   "source": [
    "padded_seq, word_index, tokenizer = my_tokenizer(X) # translate text to numerical values\n",
    "max_words = min(max_words, len(word_index)) # defines how many words to use out of the vocabulary to create an embedding matrix\n",
    "os.system('echo Tokenization completed')\n",
    "\n",
    "print(\"Sample padded sequence\", padded_seq[0]) # illustrates padding (leading zeros)\n",
    "print(\"\")\n",
    "print(\"Shape of padded_seq\", padded_seq.shape) # tensor format: (number of samples, maxlen)\n",
    "print(\"Number of words in word_index: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor execution time of different code sections\n",
    "end_prep = time.time()\n",
    "duration_data_prep = end_prep - start_prep\n",
    "runtime_dict['Data Preparation'] = round(duration_data_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Creation Embedding Matrix\n",
    "\n",
    "1. Paragram Embedding is loaded\n",
    "2. Vectors from Paragram are extracted according to questions vocabulary -> embedding matrix a)\n",
    "3. Fasttext Embedding is loaded\n",
    "4. Vectors from Fasttext are extracted according to questions vocabulary -> embeddding matrix b)\n",
    "5. Concatenation of embedding matrix a) + b) to create a strong final embedding matrix which represents each word as a 600-dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running procedure on paragram:\n",
      "   paragram loaded\n",
      "  1703755 word vectors within paragram dict\n",
      "  Embeddings_matrix created\n",
      "  Shape embedding_matrix: (216316, 300)\n",
      "  Found Embeddings for 76.87% of all words\n",
      "  num_known_words : 166277\n",
      "  num words in word_index:  216315\n",
      "  Unknown Words: 23.13%\n",
      "  Words found by PorterStemmer: 5395\n",
      "  Words found by LancasterStemmer: 6796\n",
      "  Words found by SnowballStemmer: 115\n",
      "  Words found by Lemmatisation: 93\n",
      "  Top 50 unknown words:\n",
      " ['brexit', 'cryptocurrencies', 'redmi', 'oneplus', 'coinbase', 'upwork', 'machedo', 'boruto', 'adityanath', 'gdpr', 'bnbr', 'alshamsi', 'iiest', 'unacademy', 'litecoin', 'dceu', 'tensorflow', \"qur'an\", 'zerodha', 'lnmiit', 'nicmar', 'kavalireddi', 'muoet', 'doklam', 'vajiram', '°c', 'etc…', 'elitmus', 'altcoins', 'altcoin', 'awdhesh', 'demonetisation', 'srmjee', 'zebpay', 'hackerrank', 'baahubali', 'koinex', 'mhcet', 'byju', 'gurugram', 'srmjeee', 'chromecast', 'what\\u200b', 'ftre', 'nanodegree', 'bmsce', 'skripal', 'hotstar', 'lbsnaa', 'bipc']\n",
      "\n",
      "Added embedding. First shape: (216316, 300)\n",
      "Running procedure on fasttext:\n",
      "   fasttext loaded\n",
      "  999995 word vectors within fasttext dict\n",
      "  Embeddings_matrix created\n",
      "  Shape embedding_matrix: (216316, 300)\n",
      "  Found Embeddings for 69.26% of all words\n",
      "  num_known_words : 149815\n",
      "  num words in word_index:  216315\n",
      "  Unknown Words: 30.74%\n",
      "  Words found by PorterStemmer: 4243\n",
      "  Words found by LancasterStemmer: 6318\n",
      "  Words found by SnowballStemmer: 94\n",
      "  Words found by Lemmatisation: 179\n",
      "  Top 50 unknown words:\n",
      " [\"''\", \"n't\", 'quorans', 'comedk', 'kvpy', 'quoran', 'wbjee', 'fortnite', 'marksheet', 'oneplus', 'uceed', 'bhakts', 'machedo', 'naoh', 'bnbr', 'josaa', 'alshamsi', 'chsl', 'sjws', 'devops', 'unacademy', 'aliexpress', 'tensorflow', 'jiit', \"qur'an\", 'zerodha', 'metoo', 'nmat', 'mongodb', 'lnmiit', 'angularjs', 'intps', 'nicmar', 'woocommerce', 'kavalireddi', 'hairfall', 'muoet', \"d'angelo\", 'infjs', 'doklam', 'vajiram', '°c', 'etc…', 'elitmus', 'awdhesh', 'adhaar', 'srmjee', 'modiji', 'pubg', 'zebpay']\n",
      "\n",
      "Added embedding. New shape: (216316, 600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc_embedding = None\n",
    "\n",
    "for embedding in embeddings:\n",
    "    emb_name = embedding['name']\n",
    "    emb_path = embedding['embeddings_path']\n",
    "    print(\"Running procedure on {}:\".format(emb_name))\n",
    "    \n",
    "    # loading and creation of embedding matrix\n",
    "    embedding_matrix = load_and_analyse_Embeddings(emb_name, emb_path, max_words) \n",
    "\n",
    "    # concatenation embeddings \n",
    "    conc_embedding = concatenate_embeddings(conc_embedding, embedding_matrix)\n",
    "    del embedding_matrix; gc.collect()\n",
    "\n",
    "os.system(\"echo embedding created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above coverage rates slightly differ from the reported ones because in the final prototype the testset vocabulary is used to create the embedding matrix as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429.0165157318115\n"
     ]
    }
   ],
   "source": [
    "# Monitor execution time of different code sections\n",
    "end_embeddings = time.time()\n",
    "duration_embeddings = end_embeddings - end_prep\n",
    "print(duration_embeddings)\n",
    "runtime_dict['Embeddings'] = round(duration_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "* 1 - This section contains the function which defines the model architecture\n",
    "* 2 - This section contains callback function to evaluate model performance (respectivly the learning process of the model)\n",
    "* 3 - This section contains the actual training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definition model architecture\n",
    "\n",
    "* architecture is wrapped into the function get_keras_model \n",
    "\n",
    "\n",
    "* **Embedding Layer:**\n",
    "\n",
    "    * Embedding Layer translates the integers of each input sequence into dense vectors\n",
    "      (comp. https://keras.io/layers/embeddings/)\n",
    "    * embedding_matrix translates integers into into 3D Tensores of shape:\n",
    "          * Output shape: (batch_size, sequence_length, output_dim)\n",
    "\n",
    "    * **trainable vs. not-trainable:** literature recommends not to use pre-trained embeddings in case of the availability of a large dataset. This option was evaluated: Training an own embedding based on the provided 1.3 million questions performed worse compared to each of the 4 provided pretrained word embeddings paragram, glove, fasttext and googlenews.\n",
    "    * **single vs. meta-embedding:** research recommends the use of meta-embeddings, because it outperforms the use of a single embeddings. This recommendation can be confirmed. Each use of a single embedding was outperformed by a meta-embedding technique in the Quora case. **The Concatenation of two embeddings resulted in the best results.** The concatenation of more than 2 embeddings did not lead to an improvment in model performance. For this reason, to optimize kernel runtime,  the option using only two embeddings was selected. Glove was selected as the base embedding, because it showed the best coverage on the vocabulary. Concatenation of Glove with Fasttext or Glove with Paragram resulted in the same model performance. For the final model the Concatenation of Glove and Fasttext was selected as embedding matrix. The other Meta-Embedding Technique called \"Averaging\" resulted in a faster model runtime, but lead to a slightly worse model performance.\n",
    "   \n",
    "   \n",
    "* **Model Regularization:**\n",
    "\n",
    "     * **Regularization of Recurrent Neural Networks:** typical dropout regularization is not recommended for RNN. Researchers have found out that it hinders learning prcess of a model. For this reason there exist special regularization techniques for Recurrent Neural Networks. In Keras, dropout and recurrent dropout can be applied to regularize a RNN: However both methods are not implemented in the fast CuDNNLSTM variant of a RNN. For this reason SpatialDropout1D is used to regularize the Embedding matrix.\n",
    "     * **Dropout vs. SpatialDropout1D:** Dropout is a popular technique to regularize Neural Networks. However for text data, classical dropout is not recommended, because it drops each element of the embedding matrix independently. Instead SpatialDropout1D is used which drops 1-D feature maps from the embedding matrix (completely zero out a channel). A Dropout rate of 30% has lead to the best results in the Quora case. This result is in accordance with the dropout range of 0.2-0-5 recommended by the Google Developers.\n",
    "     \n",
    "     \n",
    "* **Recurrent Layers:**\n",
    "\n",
    "     * **Bidirectional Recurrent Neural Network :** Bidirectional RNN are State-of-the-Art for the development of text classification models. All of the the following RNN implementations that exist in Keras performed worse compared to the bidirectional variant.\n",
    "             - SimpleRNN ( can not capture long-range dependencies - \"gradient vanishing problem\")\n",
    "             - LSTM-Layer (Long Short-Term Memory Layer)\n",
    "             - GRU-Layer (Gated Recurrent Units)\n",
    "             - CuDNNGRU (fast GRU implementation)\n",
    "             - CuDNNLSTM (fast LSTM implementation)\n",
    "                  \n",
    "     * **LSTM vs. CuDNNLSTM:** \n",
    "        CuDNNLSTM is a fast implementation of a LSTM. It uses the Deep Neural Network library (cuDNN) from NVIDIA. The use of CuDNNLSTM could significantly reduce the time to train the model in the Quora Case.     \n",
    "        \n",
    "     * **Number of Bi-RNN Layers:** The use of two Bi-RNN layers improved model performance (almost 1 percent point in F1) adverse only one Bi-RNN layer. The two layers obviously could increase the representation capabilites of the model.\n",
    "   \n",
    "   \n",
    "* **GlobalMaxPooling1D:**\n",
    "\n",
    "     * **GlobalMaxPooling1D or Flatten:** Both Keras Layers can be used to transform 3-D-output if RNN layers in 2-D-Output needed for the final Dense Layer \n",
    "   \n",
    "   \n",
    "* **Final Dense Layer (Classifier):**\n",
    "\n",
    "     * **activation function:** State-of-the-Art is the use of sigmoid or relu as the activation function in a binary classification model. The function returns a probability to which the model thinks a sample belongs to one class.\n",
    "     \n",
    "\n",
    "* **Model configuration:**\n",
    "   \n",
    "     * **loss function:** state-of-the-art loss function for binary classification tasks: **binary_crossentropy**\n",
    "     * **optimizer:** **rmsprop** is in most-cases a good choice according to present research papers\n",
    "     * **learning rate:** using the default learning rate of rmsprop is recommended and applied here\n",
    "     * **metrics:** must be defined, default \"accuracy\" is used but not followed up. The Accuracy IS NOT suitable to evaluate model the performance of imbalanced class datasets\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 600)         129789600 \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, None, 600)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          162304    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 64)          25088     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 129,977,057\n",
      "Trainable params: 187,457\n",
      "Non-trainable params: 129,789,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_keras_model():\n",
    "    \n",
    "    model = Sequential() # usage of Sequential model architecture\n",
    "    model.add(Embedding(input_dim = max_words+1, \n",
    "                        output_dim = conc_embedding.shape[1], \n",
    "                        weights = [conc_embedding],\n",
    "                        trainable = False)) \n",
    "    \n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    model.add(Bidirectional(CuDNNLSTM(32, return_sequences=True)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(32, return_sequences=True)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(1, activation='sigmoid')) # final -  binary classifier\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "get_keras_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definition callback function to evaluate model performance\n",
    "\n",
    "* Callback is used to monitor learning process of model during training (regarding overfitting/underfitting)\n",
    "* Callback calculates F1-Score after each model epoch.\n",
    "* Parts of code adapted from https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2\n",
    "* To calculate F1-Score distinct class labels are needed. However final classifier (sigmoid-function) only returns probabilites. For this reason during callback an F1-optimal threshold is estimated.\n",
    "* Threshold defines which probability (sample) belongs to which class\n",
    "* Suitable Evaluation metrics: Precision, Recall and F1-Score as combination of both. Since these metric functions were removed in Keras 2.0, metrics are implemented within an own callback below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetric(Callback):\n",
    "    \"\"\"\n",
    "    calculates F1-optimal threshold\n",
    "    calculates F1-Score after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create Instance at the beginning of each epoch\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.best_val_f1s = [] # collects best f1 after each epoch with best threshold\n",
    "        \n",
    "    \n",
    "    # Function called at the end of ery epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        val_predict = np.asarray(self.model.predict(self.validation_data[0])) \n",
    "        val_target = self.validation_data[1]\n",
    "        \n",
    "        # Find best threshold for prediction\n",
    "        best_f1 = 0               \n",
    "        for threshold in np.arange(0.2,0.401, 0.01):\n",
    "            val_f1 = f1_score(y_true = val_target, y_pred = val_predict >= threshold)\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "\n",
    "        \n",
    "        # Collect best F1-Scores\n",
    "        self.best_val_f1s.append(best_f1)\n",
    "        \n",
    "               \n",
    "        t1 = time.time()\n",
    "        if epoch % 2 == 0:\n",
    "            print(\"  -- epoch: {}\".format(epoch))  \n",
    "            print(\"Execution time on_epoch_end {}\".format(t1-t0))\n",
    "            os.system(\"echo  -- epoch: {}\".format(epoch))\n",
    "            os.system(\"echo Execution time on_epoch_end {}\".format(t1-t0))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training Model wih samples generated by StratifiedShuffleSplit\n",
    "\n",
    "* StratifiedKFold: training is performed \"kfold\"- time (defined by hyperparamter kfolds)\n",
    "* within each fold several epochs are run (defined by hyperparameter epochs)\n",
    "\n",
    "* Input for model are batches of integer sequences (see Data Preparation - Section 4.4)\n",
    "        * Input shape: 2D tensor(matrix): (batch_size, sequence_length).\n",
    "* each sequence has a maximum length of maxlen (here: 130)\n",
    "* a batch size of 512 comprises a good tradeoff between runtime and model performance (larger batch size -> faster learning process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split: 0  \n",
      " \n",
      "  -- epoch: 0\n",
      "Execution time on_epoch_end 77.89983057975769\n",
      "  -- epoch: 2\n",
      "Execution time on_epoch_end 79.56359624862671\n",
      "  -- epoch: 4\n",
      "Execution time on_epoch_end 78.39029622077942\n",
      "  -- epoch: 6\n",
      "Execution time on_epoch_end 79.74491834640503\n",
      "  -- epoch: 8\n",
      "Execution time on_epoch_end 77.7540123462677\n",
      "Execution time Fold 0: 2241.956442117691.\n",
      "\n",
      "Split: 1  \n",
      " \n",
      "  -- epoch: 0\n",
      "Execution time on_epoch_end 79.48705244064331\n",
      "  -- epoch: 2\n",
      "Execution time on_epoch_end 77.76795673370361\n",
      "  -- epoch: 4\n",
      "Execution time on_epoch_end 78.56958723068237\n",
      "  -- epoch: 6\n",
      "Execution time on_epoch_end 79.04062366485596\n",
      "  -- epoch: 8\n",
      "Execution time on_epoch_end 79.1352927684784\n",
      "Execution time Fold 1: 2234.369951248169.\n",
      "\n",
      "Split: 2  \n",
      " \n",
      "  -- epoch: 0\n",
      "Execution time on_epoch_end 79.88966727256775\n",
      "  -- epoch: 2\n",
      "Execution time on_epoch_end 79.14600586891174\n",
      "  -- epoch: 4\n",
      "Execution time on_epoch_end 78.38673806190491\n",
      "  -- epoch: 6\n",
      "Execution time on_epoch_end 79.69100427627563\n",
      "  -- epoch: 8\n",
      "Execution time on_epoch_end 78.4506664276123\n",
      "Execution time Fold 2: 2246.127379655838.\n"
     ]
    }
   ],
   "source": [
    "my_y_val_questions = {} # dictionary to store questions used for validation\n",
    "my_y_val_preds = {} # dictionary to collect model predictions at the end of each split\n",
    "my_y_val_targets = {} # dictionary of true classes at the end of each split\n",
    "\n",
    "my_history_dict = {} # collect accuracy of each epoch\n",
    "my_metrics_dict = {} # collect best f1 of each epoch\n",
    "\n",
    "best_f1_dict = {} # final evaluation at the end of training (after last epoch)\n",
    "best_threshold_dict = {} # collects best thresholds\n",
    "best_confmatrix_dict = {} # collects confusion_matrices\n",
    "best_precision_dict = {} # collects precison_scores\n",
    "best_recall_dict = {} # collects recall_scores\n",
    "\n",
    "\n",
    "# fold_list contains train and validation indices (folds) for each split\n",
    "'''random_state parameter is used to make results comparable/stable'''\n",
    "folds = StratifiedShuffleSplit(n_splits=kfolds, test_size=0.2, random_state=123).split(padded_seq[:total_train_samples], y[:total_train_samples])\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # dont show warnings (e.g. tensorflow version problems)\n",
    "for i, (train_indices, val_indices) in enumerate(folds):\n",
    "    start_fold = time.time()\n",
    "    \n",
    "    print('\\nSplit: {}  \\n '.format(i))\n",
    "    os.system(\"echo running split {}\".format(i))\n",
    "    \n",
    "    # Selection of samples for current fold\n",
    "    X_train, X_val = padded_seq[train_indices], padded_seq[val_indices] \n",
    "    y_train, y_val = y[train_indices], y[val_indices] \n",
    "\n",
    "    model = get_keras_model() # create new model for current split\n",
    "    my_metrics = CustomMetric() # create new metrics instance\n",
    " \n",
    "    # Training process is logged in history object for visualisation purposes\n",
    "    # within each split setting the model is trained several epochs (complete fit)\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs = model_epochs, \n",
    "                        batch_size= 512,\n",
    "                        verbose = 0, \n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks = [my_metrics])\n",
    "    \n",
    "    ############## at the end of each training process: ##################\n",
    "    \n",
    "    my_history_dict[i] = history\n",
    "    my_metrics_dict[i] = my_metrics\n",
    "    \n",
    "    # Store model prediction probabilites on validation set for evaluation purposes\n",
    "    y_val_pred = model.predict(X_val) # prediction on valiation set\n",
    "    my_y_val_questions[i] = X_val\n",
    "    my_y_val_preds[i] = y_val_pred \n",
    "    my_y_val_targets[i] = y_val\n",
    "    \n",
    "    # Find best threshold for prediction - this threshold later is used for the submission file predictions\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.arange(0.1,0.5, 0.01):\n",
    "        # calucate f1 score for allowed thresholds\n",
    "        f1_score_threshold = f1_score(y_true = y_val ,\n",
    "                                              y_pred = y_val_pred >= threshold) # 0 or 1\n",
    "        if f1_score_threshold > best_f1:\n",
    "            best_f1 = f1_score_threshold\n",
    "            best_threshold = threshold\n",
    "            best_f1_dict[i] = best_f1\n",
    "            best_threshold_dict[i] = best_threshold\n",
    "    \n",
    "    # Use threshold of the the best f1 score to calculate confusion matrix, precision and recall\n",
    "    best_confmatrix_dict[i] = confusion_matrix(y_true = y_val ,y_pred = y_val_pred >= best_threshold, labels=[0, 1])\n",
    "    best_precision_dict[i] = precision_score(y_true = y_val ,y_pred = y_val_pred >= best_threshold, average='binary') \n",
    "    best_recall_dict[i] = recall_score(y_true = y_val ,y_pred = y_val_pred >= best_threshold, average='binary')\n",
    "            \n",
    "    stop_fold = time.time()\n",
    "    print(\"Execution time Fold {}: {}.\".format(i, (stop_fold - start_fold)))\n",
    "    os.system(\"echo Execution time Fold {}: {}.\".format(i, (stop_fold - start_fold))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 0 : Best F1 score: 0.6844 reached with a threshold of 0.4400\n",
      "Split: 1 : Best F1 score: 0.6817 reached with a threshold of 0.3900\n",
      "Split: 2 : Best F1 score: 0.6839 reached with a threshold of 0.3700\n",
      "\n",
      "Threshold for prediction: 0.4000\n",
      "Average F1-Score: 0.683\n"
     ]
    }
   ],
   "source": [
    "thresh_avg = 0\n",
    "thresh_sum = 0\n",
    "f1_avg = 0\n",
    "f1_sum = 0\n",
    "\n",
    "for key, value in best_f1_dict.items():\n",
    "    print(\"Split: {} : Best F1 score: {:6.4f} reached with a threshold of {:6.4f}\"\n",
    "          .format(key, best_f1_dict[key], best_threshold_dict[key]))\n",
    "    thresh_sum += best_threshold_dict[key] \n",
    "    thresh_avg = thresh_sum/kfolds\n",
    "    f1_sum += best_f1_dict[key] \n",
    "    f1_avg = f1_sum/kfolds\n",
    "   \n",
    "print(\"\")\n",
    "print(\"Threshold for prediction: {:6.4f}\".format(thresh_avg))\n",
    "print(\"Average F1-Score: {:5.3f}\".format(f1_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "* 1 - This section contains the evaluation of callback results (loss function and F1-Score) <b>(cf. chapter 9.2.2 in thesis)</b>\n",
    "* 2 - Evaluation of model predictions based on metrics for binary classification tasks (precision ,recall, confusin matrix) <b>(cf. chapter 9.2.3 in thesis)</b>\n",
    "* 3 - This section inspects model prediciton in detail and aims at understanding what kind of error the model makes <b>(cf. chapter 9.2.4 in thesis)</b>\n",
    "* 4 - Evaluation of kernel runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Evaluation of callback results (regarding Over-/Underfitting) \n",
    "\n",
    "* For the evaluation of unbalanced datasets the accuracy as implemented in SKLEARN's function cross_val_score() is NOT recommended\n",
    "* A high F1 score is the target in this competition and combines precision and recall\n",
    "* **Plotting information were captured during training by History and Callback Object**\n",
    "* **Cross Validation** is used to evaluate the model regarding Over/Underfitting\n",
    "* **Evaluation based on loss function and F1-Score captured during training for each model epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 0 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 2 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in my_history_dict:\n",
    "    \n",
    "    print('Split: {} '.format(i))\n",
    "    loss = my_history_dict[i].history['loss']\n",
    "    val_loss = my_history_dict[i].history['val_loss']\n",
    "    epochs = np.arange(1, len(loss) +1, 1) # x-axis\n",
    "\n",
    "    # Plotting:\n",
    "    f = plt.figure(figsize=(10,3))\n",
    "    # plots loss\n",
    "    f.add_subplot(1, 2, 1) # number of rows, number of columns,subplot you're currently on.\n",
    "    plt.xticks(epochs)\n",
    "    plt.plot(epochs, loss, 'bo', label='Loss Training', color = 'black')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Loss Validation')\n",
    "    plt.title('Loss function Training / Validation')\n",
    "    plt.legend()\n",
    " \n",
    "    # plots f1 score\n",
    "    f.add_subplot(1, 2, 2)\n",
    "    best_val_f1s = my_metrics_dict[i].best_val_f1s\n",
    "   # plt.figure()\n",
    "    plt.xticks(epochs)\n",
    "    plt.plot(epochs, best_val_f1s, 'b', label='F1 Validation')\n",
    "    plt.title('F1 Validation')\n",
    "    plt.legend()\n",
    "    \n",
    "    #plt.subplots_adjust(wspace=0.30) # width reserved for blank space between subplots\n",
    "    f.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **The Model starts to overfit at around epoch 6/7.** Loss functions of training and validation diverge. The F1-Score does not improve anymore. The prototype starts to model random noise in the training data (high variance) and learns irrelevant patterns. These relations are a barrier for the model to generalize well on the unseen validation data. For this reason training the model longer than 7 epochs does not make sense. \n",
    "* However, strong overfitting characterized by a steep increase of the loss function on validation set can not be observed (slightly in epoch 10 of split 0). \n",
    "* **stopping training process at around epoch 7 poses a good trade-off** between Underfitting (high bias, low variance) and Overfitting (low bias, high variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6732.082716226578\n"
     ]
    }
   ],
   "source": [
    "train_and_eval= time.time()\n",
    "duration_train_and_eval = train_and_eval - end_embeddings\n",
    "print(duration_train_and_eval)\n",
    "runtime_dict['Modeling'] = round(duration_train_and_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluation of model predictions based on metrics for binary classification tasks\n",
    "\n",
    "* As illustrated in the Data Exploration Kernel the Quora dataset is a highly imbalanced dataset. The insincere class (1) only has a small number of samples. For this the keras model has to be careful predicting the toxic class. There are two imporant aspects that should be examined:\n",
    "\n",
    "        a) Does the model only label a sample as class 1, if it is quite sure ? \n",
    "        b) Or does the model make a lot of class 1 predictions in order to cover most of class 1   \n",
    "           members?\n",
    "        \n",
    "*** Confusion matrix, precision and recall is calculated and interpreted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Split: 0 \n",
      " Best F1 score: 0.6844 reached with a threshold of 0.4400 \n",
      "\n",
      " Confusion Matrix    Precision    Recall  \n",
      " [[238444   6619]\n",
      " [  4312  11850]]            0.642     0.733\n",
      "\n",
      " Split: 1 \n",
      " Best F1 score: 0.6817 reached with a threshold of 0.3900 \n",
      "\n",
      " Confusion Matrix    Precision    Recall  \n",
      " [[238723   6340]\n",
      " [  4526  11636]]            0.647     0.720\n",
      "\n",
      " Split: 2 \n",
      " Best F1 score: 0.6839 reached with a threshold of 0.3700 \n",
      "\n",
      " Confusion Matrix    Precision    Recall  \n",
      " [[238473   6590]\n",
      " [  4339  11823]]            0.642     0.732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix, Precision and Recall after each Split\n",
    "for key, value in best_f1_dict.items():\n",
    "    print(\" Split: {} \\n Best F1 score: {:6.4f} reached with a threshold of {:6.4f} \\n\"\n",
    "          .format(key, best_f1_dict[key], best_threshold_dict[key]))\n",
    "    print(\" Confusion Matrix    Precision    Recall  \\n {}{:17.3f}{:10.3f}\\n\".format(best_confmatrix_dict[key],\n",
    "                                                                                     best_precision_dict[key],\n",
    "                                                                                     best_recall_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inspecting model predictions in detail\n",
    "\n",
    "* So far, evaluated model predictions always were transformed into binary class labels based on a threshold. This helps to get a basic understanding about model performance, but does do give enough insights to understand why the model behaves as it does. This section is targeted to **understand why the model makes errors**. Questions to be answered are:\n",
    "        a) What are insincere questions where the model strongly believes to be sincere ?\n",
    "        b) What are sincere questions where the model strongly believes to be insincere ?\n",
    "        c) What are insincere questions where the model is uncertain how to classify ?\n",
    "        d) What are sincere questions where the model is uncertain how to classify?\n",
    "    \n",
    "* Moreover\n",
    "        e) what kind to questions the model is able to classify correctly with high confidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for e.g. Split 1 predictions \n",
    "i = 1\n",
    "\n",
    "q = tokenizer.sequences_to_texts(my_y_val_questions[i]) # transform integer sequences back to questions after preprocessing\n",
    "\n",
    "# Creates data for DataFrame\n",
    "d = {'validation_questions (after preprocessing)': q,\n",
    "     'true_labels': my_y_val_targets[i],\n",
    "     'predicted_probabilities': list(my_y_val_preds[i]),\n",
    "     'predicted_labels': list(my_y_val_preds[i] >= best_threshold_dict[i]),\n",
    "    }\n",
    "preds_in_detail = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_questions (after preprocessing)</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>what is driving the adoption of devops today</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0004898608]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>is the key to getting rich leverage</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00014063716]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>what is the best web hosting providers for web design agency</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00036928058]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>how can you make glow in the dark crystals</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00024014711]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>who is more corrupt jabba the hutt or palpatine</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2645591]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     validation_questions (after preprocessing)  true_labels  \\\n",
       "0                  what is driving the adoption of devops today            0   \n",
       "1                           is the key to getting rich leverage            0   \n",
       "2  what is the best web hosting providers for web design agency            0   \n",
       "3                    how can you make glow in the dark crystals            0   \n",
       "4               who is more corrupt jabba the hutt or palpatine            0   \n",
       "\n",
       "  predicted_probabilities  predicted_labels  \n",
       "0          [0.0004898608]                 0  \n",
       "1         [0.00014063716]                 0  \n",
       "2         [0.00036928058]                 0  \n",
       "3         [0.00024014711]                 0  \n",
       "4             [0.2645591]                 0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_in_detail.predicted_labels = preds_in_detail.predicted_labels.astype(int)\n",
    "preds_in_detail.true_labels = preds_in_detail.true_labels.astype(int)\n",
    "preds_in_detail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####       a) What are insincere questions where the model strongly believes to be sincere ?\n",
    "\n",
    "* This is the most important question. A machine learning model for toxic coment classification should be able to clearly identify insincere questions. Attacks against individuals or groups must be reduced to the minimum to keep online conversations fruitful. It is better if the model identifies some non-toxic questions as toxic than the other way around. \n",
    "\n",
    "* Code section from above were necessary information for this section were gathered:\n",
    "        y_val_pred = model.predict(X_val) # prediction on valiation set\n",
    "        my_y_val_questions[i] = X_val\n",
    "        my_y_val_preds[i] = y_val_pred \n",
    "        my_y_val_targets[i] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_questions (after preprocessing)</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>wrong label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>185564</td>\n",
       "      <td>why do fat females wear shorts that show their buttocks</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38992476]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125733</td>\n",
       "      <td>how can one have sex with a woman without being accused of rape is a written contract enough</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38980186]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14281</td>\n",
       "      <td>is it categorically wrong to wish that all people who are of west european descent were dead</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38976493]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81460</td>\n",
       "      <td>is pseudo feminism strengthening in india</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3895115]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>can the bjp followers or its bakths say the reason why they support bjp are they supporting wholeheartedly or just for any reason</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3895068]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235569</td>\n",
       "      <td>is it true that victoria 's secret models are all high priced prostitutes like some people have claimed</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38945776]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128642</td>\n",
       "      <td>why is physics still taught in schools when it is a pseudoscience and people have demonstrated glitches where the laws of physics are unstable since people are witnessing objects or people instantaneously ceasing to exist right in front of them</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38944232]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3529</td>\n",
       "      <td>where do i find russians for sex</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38922867]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83650</td>\n",
       "      <td>what should a normal penis look like for a fifteen year old</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38922712]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139151</td>\n",
       "      <td>what is the general attitude of white men towards asian men on grindr</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3890962]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                  validation_questions (after preprocessing)  \\\n",
       "185564                                                                                                                                                                                               why do fat females wear shorts that show their buttocks   \n",
       "125733                                                                                                                                                          how can one have sex with a woman without being accused of rape is a written contract enough   \n",
       "14281                                                                                                                                                           is it categorically wrong to wish that all people who are of west european descent were dead   \n",
       "81460                                                                                                                                                                                                              is pseudo feminism strengthening in india   \n",
       "2330                                                                                                                       can the bjp followers or its bakths say the reason why they support bjp are they supporting wholeheartedly or just for any reason   \n",
       "235569                                                                                                                                               is it true that victoria 's secret models are all high priced prostitutes like some people have claimed   \n",
       "128642  why is physics still taught in schools when it is a pseudoscience and people have demonstrated glitches where the laws of physics are unstable since people are witnessing objects or people instantaneously ceasing to exist right in front of them   \n",
       "3529                                                                                                                                                                                                                        where do i find russians for sex   \n",
       "83650                                                                                                                                                                                            what should a normal penis look like for a fifteen year old   \n",
       "139151                                                                                                                                                                                 what is the general attitude of white men towards asian men on grindr   \n",
       "\n",
       "        true_labels predicted_probabilities  predicted_labels  wrong label  \n",
       "185564            1            [0.38992476]                 0         True  \n",
       "125733            1            [0.38980186]                 0         True  \n",
       "14281             1            [0.38976493]                 0         True  \n",
       "81460             1             [0.3895115]                 0         True  \n",
       "2330              1             [0.3895068]                 0         True  \n",
       "235569            1            [0.38945776]                 0         True  \n",
       "128642            1            [0.38944232]                 0         True  \n",
       "3529              1            [0.38922867]                 0         True  \n",
       "83650             1            [0.38922712]                 0         True  \n",
       "139151            1             [0.3890962]                 0         True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting Wrong Labels: true class is toxic (1), but models predics sincere (0)\n",
    "wrong_labels = preds_in_detail\n",
    "wrong_labels['wrong label'] = (preds_in_detail['true_labels'] == 1) & (preds_in_detail['predicted_labels'] == 0) \n",
    "wrong_labels = wrong_labels[wrong_labels['wrong label'] == True]\n",
    "\n",
    "# Top 10 \n",
    "wrong_labels.sort_values(by=['predicted_probabilities'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10191"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del wrong_labels; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) What are sincere questions where the network strongly believes to be insincere ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_questions (after preprocessing)</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>wrong label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>129706</td>\n",
       "      <td>why are all malayalee 's such tamil freaks</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9840108]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166737</td>\n",
       "      <td>why dont't girls like small dicks</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.98230946]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214294</td>\n",
       "      <td>is it ok to want to have sex with my mom</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9815904]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217305</td>\n",
       "      <td>was warren harding castrated</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9809592]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189700</td>\n",
       "      <td>if i put a gun to your head and ordered you to castrate your dog without anaesthesia would you complete the procedure</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9788278]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15513</td>\n",
       "      <td>why are men such fucking piles of dog shit</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.97826886]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183722</td>\n",
       "      <td>what happens if you have sex with a dog</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.97742647]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184107</td>\n",
       "      <td>can mom have sex with her own son</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9753533]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202786</td>\n",
       "      <td>does father daughter mother son relationships trump father son and mother daughter relationships</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.97486216]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166403</td>\n",
       "      <td>if i am gay will i go to hell</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.97135]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   validation_questions (after preprocessing)  \\\n",
       "129706                                                                             why are all malayalee 's such tamil freaks   \n",
       "166737                                                                                      why dont't girls like small dicks   \n",
       "214294                                                                               is it ok to want to have sex with my mom   \n",
       "217305                                                                                           was warren harding castrated   \n",
       "189700  if i put a gun to your head and ordered you to castrate your dog without anaesthesia would you complete the procedure   \n",
       "15513                                                                              why are men such fucking piles of dog shit   \n",
       "183722                                                                                what happens if you have sex with a dog   \n",
       "184107                                                                                      can mom have sex with her own son   \n",
       "202786                       does father daughter mother son relationships trump father son and mother daughter relationships   \n",
       "166403                                                                                          if i am gay will i go to hell   \n",
       "\n",
       "        true_labels predicted_probabilities  predicted_labels  wrong label  \n",
       "129706            0             [0.9840108]                 1         True  \n",
       "166737            0            [0.98230946]                 1         True  \n",
       "214294            0             [0.9815904]                 1         True  \n",
       "217305            0             [0.9809592]                 1         True  \n",
       "189700            0             [0.9788278]                 1         True  \n",
       "15513             0            [0.97826886]                 1         True  \n",
       "183722            0            [0.97742647]                 1         True  \n",
       "184107            0             [0.9753533]                 1         True  \n",
       "202786            0            [0.97486216]                 1         True  \n",
       "166403            0               [0.97135]                 1         True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting Wrong Labels: true class is bot-toxic (1), but models predics insincere (1)\n",
    "wrong_labels = preds_in_detail\n",
    "wrong_labels['wrong label'] = (preds_in_detail['true_labels'] == 0) & (preds_in_detail['predicted_labels'] == 1) \n",
    "wrong_labels = wrong_labels[wrong_labels['wrong label'] == True]\n",
    "\n",
    "# Top 10 \n",
    "wrong_labels.sort_values(by=['predicted_probabilities'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del wrong_labels; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) What are insincere questions where the model is uncertain how to classify ?\n",
    "\n",
    "* uncertainty in this case means, that the predicted probability of a sample is at or close around the decision boundary (threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds top N closest numbers to threshold of split i\n",
    "x0 = best_threshold_dict[i]\n",
    "n = 100\n",
    "mylist = preds_in_detail['predicted_probabilities']\n",
    "n_closest = heapq.nsmallest(n, mylist, key=lambda x: abs(x-x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_questions (after preprocessing)</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>wrong label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>593</td>\n",
       "      <td>why does pakistan support terrorism</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3911306]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>can the bjp followers or its bakths say the reason why they support bjp are they supporting wholeheartedly or just for any reason</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3895068]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3529</td>\n",
       "      <td>where do i find russians for sex</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38922867]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3637</td>\n",
       "      <td>when trump receives his orders from putin do they speak in russian or english</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.39123565]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10892</td>\n",
       "      <td>why should not a real estate mogul billionaire playboy who won the presidency be a role model for your kids</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3882376]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14281</td>\n",
       "      <td>is it categorically wrong to wish that all people who are of west european descent were dead</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38976493]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24269</td>\n",
       "      <td>does anyone think that the trump supporters actually read and understand any of the numerous enlightening answers supplied by quorans</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3906639]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26407</td>\n",
       "      <td>should anti gunners be asked to leave the usa</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.39233184]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36538</td>\n",
       "      <td>why are american conservatives generally opposed of immigration to the united stated when their ancestors were immigrants</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.38878343]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46694</td>\n",
       "      <td>if women do not want to be attractive to men why do they wear makeup</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.39173633]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  validation_questions (after preprocessing)  \\\n",
       "593                                                                                                      why does pakistan support terrorism   \n",
       "2330       can the bjp followers or its bakths say the reason why they support bjp are they supporting wholeheartedly or just for any reason   \n",
       "3529                                                                                                        where do i find russians for sex   \n",
       "3637                                                           when trump receives his orders from putin do they speak in russian or english   \n",
       "10892                            why should not a real estate mogul billionaire playboy who won the presidency be a role model for your kids   \n",
       "14281                                           is it categorically wrong to wish that all people who are of west european descent were dead   \n",
       "24269  does anyone think that the trump supporters actually read and understand any of the numerous enlightening answers supplied by quorans   \n",
       "26407                                                                                          should anti gunners be asked to leave the usa   \n",
       "36538              why are american conservatives generally opposed of immigration to the united stated when their ancestors were immigrants   \n",
       "46694                                                                   if women do not want to be attractive to men why do they wear makeup   \n",
       "\n",
       "       true_labels predicted_probabilities  predicted_labels  wrong label  \n",
       "593              1             [0.3911306]                 1         True  \n",
       "2330             1             [0.3895068]                 0         True  \n",
       "3529             1            [0.38922867]                 0         True  \n",
       "3637             1            [0.39123565]                 1         True  \n",
       "10892            1             [0.3882376]                 0         True  \n",
       "14281            1            [0.38976493]                 0         True  \n",
       "24269            1             [0.3906639]                 1         True  \n",
       "26407            1            [0.39233184]                 1         True  \n",
       "36538            1            [0.38878343]                 0         True  \n",
       "46694            1            [0.39173633]                 1         True  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting Wrong Labels: true class is toxic (1), but models is unsure (probablity close to threshold)\n",
    "wrong_labels = preds_in_detail\n",
    "wrong_labels['wrong label'] = (preds_in_detail['true_labels'] == 1) & (preds_in_detail.predicted_probabilities.isin(n_closest) )\n",
    "wrong_labels = wrong_labels[wrong_labels['wrong label'] == True]\n",
    "\n",
    "# Top 10 \n",
    "wrong_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del wrong_labels; gc.collect() # Garbage Cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) What are sincere questions where the model is uncertain how to classify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_questions (after preprocessing)</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>wrong label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9256</td>\n",
       "      <td>are poverty politics and double taxation the major reasons why americans do not relocate to other countries for work or living</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.38807452]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11097</td>\n",
       "      <td>why do you hate our president trump</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.39143494]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15463</td>\n",
       "      <td>is laundering russian mob money a crime</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.39229092]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17888</td>\n",
       "      <td>why does quora hold so many of my answers in draft form it is frustrating and infuriating to have to go back a second time to submit them quora is not user friendly and is looking to chase users away and lose customers</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.3911189]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26169</td>\n",
       "      <td>why are people in irvine so uptight</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.3892291]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57708</td>\n",
       "      <td>should more men become public school teachers</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.38813913]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69157</td>\n",
       "      <td>is it is reasonable to ask whether the united states should put soldiers and resources at risk to rescue non military american citizens who have knowingly and deliberately and in my view foolishly ventured into dangerous regions like afganistan</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.3894621]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69828</td>\n",
       "      <td>what are the best memes of white people calling the cops on minorities</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.39059135]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75241</td>\n",
       "      <td>under who were indians better off the muslim rulers or the mughals</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.38950536]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85092</td>\n",
       "      <td>why are so many gujaratis doing in china these days</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.388639]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                 validation_questions (after preprocessing)  \\\n",
       "9256                                                                                                                         are poverty politics and double taxation the major reasons why americans do not relocate to other countries for work or living   \n",
       "11097                                                                                                                                                                                                                   why do you hate our president trump   \n",
       "15463                                                                                                                                                                                                               is laundering russian mob money a crime   \n",
       "17888                            why does quora hold so many of my answers in draft form it is frustrating and infuriating to have to go back a second time to submit them quora is not user friendly and is looking to chase users away and lose customers   \n",
       "26169                                                                                                                                                                                                                   why are people in irvine so uptight   \n",
       "57708                                                                                                                                                                                                         should more men become public school teachers   \n",
       "69157  is it is reasonable to ask whether the united states should put soldiers and resources at risk to rescue non military american citizens who have knowingly and deliberately and in my view foolishly ventured into dangerous regions like afganistan   \n",
       "69828                                                                                                                                                                                what are the best memes of white people calling the cops on minorities   \n",
       "75241                                                                                                                                                                                    under who were indians better off the muslim rulers or the mughals   \n",
       "85092                                                                                                                                                                                                   why are so many gujaratis doing in china these days   \n",
       "\n",
       "       true_labels predicted_probabilities  predicted_labels  wrong label  \n",
       "9256             0            [0.38807452]                 0         True  \n",
       "11097            0            [0.39143494]                 1         True  \n",
       "15463            0            [0.39229092]                 1         True  \n",
       "17888            0             [0.3911189]                 1         True  \n",
       "26169            0             [0.3892291]                 0         True  \n",
       "57708            0            [0.38813913]                 0         True  \n",
       "69157            0             [0.3894621]                 0         True  \n",
       "69828            0            [0.39059135]                 1         True  \n",
       "75241            0            [0.38950536]                 0         True  \n",
       "85092            0              [0.388639]                 0         True  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting Wrong Labels: true class is not toxic (0), but models is unsure (probablity close to threshold)\n",
    "wrong_labels = preds_in_detail\n",
    "wrong_labels['wrong label'] = (preds_in_detail['true_labels'] == 0) & (preds_in_detail.predicted_probabilities.isin(n_closest) )\n",
    "wrong_labels = wrong_labels[wrong_labels['wrong label'] == True]\n",
    "\n",
    "# Top 10 \n",
    "wrong_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del wrong_labels; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) what kind to questions the model is able to classify correctly with high confidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_questions (after preprocessing)</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>wrong label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>249454</td>\n",
       "      <td>which language is used in developing ai is mechanical engineer can develop and be a part of ai developing</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.208352e-05]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227962</td>\n",
       "      <td>what are some literary devices used by nikolaos van dam as an author</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.4169683e-05]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203735</td>\n",
       "      <td>how do dynamically typed languages affect expressiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.4706125e-05]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143197</td>\n",
       "      <td>what fraction of research papers in machine learning and nlp are used in practice</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.4944544e-05]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257837</td>\n",
       "      <td>where can i learn credit risk analytics and modelling using sas</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.527237e-05]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       validation_questions (after preprocessing)  \\\n",
       "249454  which language is used in developing ai is mechanical engineer can develop and be a part of ai developing   \n",
       "227962                                       what are some literary devices used by nikolaos van dam as an author   \n",
       "203735                                                   how do dynamically typed languages affect expressiveness   \n",
       "143197                          what fraction of research papers in machine learning and nlp are used in practice   \n",
       "257837                                            where can i learn credit risk analytics and modelling using sas   \n",
       "\n",
       "        true_labels predicted_probabilities  predicted_labels  wrong label  \n",
       "249454            0          [2.208352e-05]                 0        False  \n",
       "227962            0         [2.4169683e-05]                 0        False  \n",
       "203735            0         [2.4706125e-05]                 0        False  \n",
       "143197            0         [2.4944544e-05]                 0        False  \n",
       "257837            0          [2.527237e-05]                 0        False  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 were the model is quite sure that sample belongs to class 0\n",
    "preds_in_detail.sort_values(by = ['predicted_probabilities'], ascending = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_questions (after preprocessing)</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>wrong label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>215502</td>\n",
       "      <td>why does quora suck so badly i have to create an account eat a bunch of dicks you cunts</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9912437]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85977</td>\n",
       "      <td>if fucked my son he has such a nice cock i want it again what is wrong with me</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9901062]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101145</td>\n",
       "      <td>why is quora so full of liberal whiny bitches</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9899827]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229728</td>\n",
       "      <td>if han solo asked chewbacca to castrate himself would he</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9890116]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96603</td>\n",
       "      <td>if han solo asked luke skywalker to castrate himself would he</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9886483]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     validation_questions (after preprocessing)  \\\n",
       "215502  why does quora suck so badly i have to create an account eat a bunch of dicks you cunts   \n",
       "85977            if fucked my son he has such a nice cock i want it again what is wrong with me   \n",
       "101145                                            why is quora so full of liberal whiny bitches   \n",
       "229728                                 if han solo asked chewbacca to castrate himself would he   \n",
       "96603                             if han solo asked luke skywalker to castrate himself would he   \n",
       "\n",
       "        true_labels predicted_probabilities  predicted_labels  wrong label  \n",
       "215502            1             [0.9912437]                 1        False  \n",
       "85977             1             [0.9901062]                 1        False  \n",
       "101145            1             [0.9899827]                 1        False  \n",
       "229728            1             [0.9890116]                 1        False  \n",
       "96603             1             [0.9886483]                 1        False  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 were the model is quite sure that sample belongs to class 1\n",
    "preds_in_detail.sort_values(by = ['predicted_probabilities'], ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del preds_in_detail; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation of the kernel runtime\n",
    "\n",
    "* inspecting especially time for model training, which is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"e15b25b7-5918-48d4-9bb0-065f4dba7f18\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"e15b25b7-5918-48d4-9bb0-065f4dba7f18\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'e15b25b7-5918-48d4-9bb0-065f4dba7f18',\n",
       "                        [{\"marker\": {\"color\": \"rgba(38, 24, 74, 0.8)\", \"line\": {\"color\": \"rgb(248, 248, 249)\"}}, \"orientation\": \"h\", \"type\": \"bar\", \"width\": 0.4, \"x\": [580], \"y\": [\"Runtime [s]\"]}, {\"marker\": {\"color\": \"rgba(71, 58, 131, 0.8)\", \"line\": {\"color\": \"rgb(248, 248, 249)\"}}, \"orientation\": \"h\", \"type\": \"bar\", \"width\": 0.4, \"x\": [429], \"y\": [\"Runtime [s]\"]}, {\"marker\": {\"color\": \"rgba(122, 120, 168, 0.8)\", \"line\": {\"color\": \"rgb(248, 248, 249)\"}}, \"orientation\": \"h\", \"type\": \"bar\", \"width\": 0.4, \"x\": [6732], \"y\": [\"Runtime [s]\"]}],\n",
       "                        {\"annotations\": [{\"align\": \"right\", \"font\": {\"color\": \"rgb(67, 67, 67)\", \"family\": \"Arial\", \"size\": 14}, \"showarrow\": false, \"text\": \"Runtime [s]\", \"x\": 0.14, \"xanchor\": \"right\", \"xref\": \"paper\", \"y\": \"Runtime [s]\", \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(248, 248, 255)\", \"family\": \"Arial\", \"size\": 14}, \"showarrow\": false, \"text\": \"580\", \"x\": 290.0, \"xref\": \"x\", \"y\": \"Runtime [s]\", \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(67, 67, 67)\", \"family\": \"Arial\", \"size\": 14}, \"showarrow\": false, \"text\": \"Data Preparation\", \"x\": 290.0, \"xref\": \"x\", \"y\": 1.1, \"yref\": \"paper\"}, {\"font\": {\"color\": \"rgb(248, 248, 255)\", \"family\": \"Arial\", \"size\": 14}, \"showarrow\": false, \"text\": \"429\", \"x\": 794.5, \"xref\": \"x\", \"y\": \"Runtime [s]\", \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(67, 67, 67)\", \"family\": \"Arial\", \"size\": 14}, \"showarrow\": false, \"text\": \"Embeddings\", \"x\": 794.5, \"xref\": \"x\", \"y\": 1.1, \"yref\": \"paper\"}, {\"font\": {\"color\": \"rgb(248, 248, 255)\", \"family\": \"Arial\", \"size\": 14}, \"showarrow\": false, \"text\": \"6732\", \"x\": 4375.0, \"xref\": \"x\", \"y\": \"Runtime [s]\", \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(67, 67, 67)\", \"family\": \"Arial\", \"size\": 14}, \"showarrow\": false, \"text\": \"Modeling\", \"x\": 4375.0, \"xref\": \"x\", \"y\": 1.1, \"yref\": \"paper\"}], \"barmode\": \"stack\", \"margin\": {\"b\": 40, \"l\": 120, \"r\": 10, \"t\": 140}, \"paper_bgcolor\": \"rgb(248, 248, 255)\", \"plot_bgcolor\": \"rgb(248, 248, 255)\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"domain\": [0.15, 1], \"showgrid\": false, \"showline\": false, \"showticklabels\": true, \"zeroline\": false}, \"yaxis\": {\"showgrid\": false, \"showline\": false, \"showticklabels\": false, \"zeroline\": false}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e15b25b7-5918-48d4-9bb0-065f4dba7f18');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "top_labels = ['Data Preparation', 'Embeddings', 'Modeling']\n",
    "\n",
    "colors = ['rgba(38, 24, 74, 0.8)', 'rgba(71, 58, 131, 0.8)','rgba(122, 120, 168, 0.8)']\n",
    "\n",
    "x_data = []\n",
    "for phase, dur in runtime_dict.items():\n",
    "    x_data.append(dur)\n",
    "x_data = [x_data]\n",
    "\n",
    "y_data = ['Runtime [s]']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(0, len(x_data[0])):\n",
    "    for xd, yd in zip(x_data, y_data):\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=[xd[i]], y=[yd],\n",
    "            orientation='h',\n",
    "            width = 0.4, # width of bars\n",
    "            marker=dict(\n",
    "                color=colors[i],\n",
    "                line=dict(color='rgb(248, 248, 249)')\n",
    "            )\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "        zeroline=False,\n",
    "        domain=[0.15, 1]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=False,\n",
    "        zeroline=False,\n",
    "    ),\n",
    "    barmode='stack',\n",
    "    paper_bgcolor='rgb(248, 248, 255)',\n",
    "    plot_bgcolor='rgb(248, 248, 255)',\n",
    "    margin=dict(l=120, r=10, t=140, b=40),\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "annotations = []\n",
    "\n",
    "for yd, xd in zip(y_data, x_data):\n",
    "    # labeling the y-axis\n",
    "    annotations.append(dict(xref='paper', yref='y',\n",
    "                            x=0.14, y=yd,\n",
    "                            xanchor='right',\n",
    "                            text=str(yd),\n",
    "                            font=dict(family='Arial', size=14,\n",
    "                                      color='rgb(67, 67, 67)'),\n",
    "                            showarrow=False, align='right'))\n",
    "    # labeling the first percentage of each bar (x_axis)\n",
    "    annotations.append(dict(xref='x', yref='y',\n",
    "                            x=xd[0] / 2, y=yd,\n",
    "                            text=str(xd[0]),\n",
    "                            font=dict(family='Arial', size=14,\n",
    "                                      color='rgb(248, 248, 255)'),\n",
    "                            showarrow=False))\n",
    "    # labeling the first Likert scale (on the top)\n",
    "    if yd == y_data[-1]:\n",
    "        annotations.append(dict(xref='x', yref='paper',\n",
    "                                x=xd[0] / 2, y=1.1,\n",
    "                                text=top_labels[0],\n",
    "                                font=dict(family='Arial', size=14,\n",
    "                                          color='rgb(67, 67, 67)'),\n",
    "                                showarrow=False))\n",
    "    space = xd[0]\n",
    "    for i in range(1, len(xd)):\n",
    "            # labeling the rest of percentages for each bar (x_axis)\n",
    "            annotations.append(dict(xref='x', yref='y',\n",
    "                                    x=space + (xd[i]/2), y=yd,\n",
    "                                    text=str(xd[i]),\n",
    "                                    font=dict(family='Arial', size=14,\n",
    "                                              color='rgb(248, 248, 255)'),\n",
    "                                    showarrow=False))\n",
    "            # labeling the Likert scale\n",
    "            if yd == y_data[-1]:\n",
    "                annotations.append(dict(xref='x', yref='paper',\n",
    "                                        x=space + (xd[i]/2), y=1.1,\n",
    "                                        text=top_labels[i],\n",
    "                                        font=dict(family='Arial', size=14,\n",
    "                                                  color='rgb(67, 67, 67)'),\n",
    "                                        showarrow=False))\n",
    "            space += xd[i]\n",
    "\n",
    "fig.update_layout(annotations=annotations)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission (Prediction)\n",
    "\n",
    "* Test data was loaded in section \"Execution Data Preparation Functions\" - 4.1\n",
    "* Preprocessing Function was applied to test data in section \"Execution Data Preparation Functions\" - 4.2\n",
    "* Test data questions were extracted in section \"Execution Data Preparation Functions\" - 4.3\n",
    "* My_tokenizer function was applied to test data in section \"Execution Data Preparation Functions\" - 4.4\n",
    "\n",
    "\n",
    "  **-> Test data is available as padded integer sequences**\n",
    "     \n",
    "\n",
    "* 1 - This section contains the model prediction to create the submission file\n",
    "* 2 - This section saved the submission file as kernel output to get a score within the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length numpy array testset: 375806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   16,\n",
       "         10,   53,   70,  118,   96,   53, 1737,   11, 3984,   34,   48,\n",
       "         35,   98,    4,  706, 1450,    7, 2180,   11,  286], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq_test = padded_seq[total_train_samples:]\n",
    "print(\"Length numpy array testset:\", len(padded_seq_test))\n",
    "padded_seq_test[0] #sfirst sample a predictipn is made for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model prediction\n",
    "\n",
    "* model predicts a class probability\n",
    "* class probability is converted to distinct class labels via a threshold, resulting in question labeling as\n",
    "         0 (insincere questions) or 1 (sincere questions)\n",
    "* the optimal threshold was examined during model training (Modeling -  section 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 21s 56us/step\n",
      "Submission dataframe has the same length as test dataframe with shape:(375806, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction\n",
       "0  0000163e3ea7c7a74cd7           1\n",
       "1  00002bd4fb5d505b9161           0\n",
       "2  00007756b4a147d2b0b3           0\n",
       "3  000086e4b7e1c7146103           0\n",
       "4  0000c4c3fbe8785a3090           0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Prediction\n",
    "preds = model.predict(padded_seq_test, batch_size = 512, verbose = 1)\n",
    "final_preds = preds\n",
    "\n",
    "# Create a submission dataframe and append relevant columns\n",
    "submission = pd.DataFrame()\n",
    "submission['qid'] = test['qid'].values\n",
    "submission['prediction'] = (final_preds > 0.38).astype(int) # round sigmoid results to integers\n",
    "\n",
    "# Do test and my submission Dataframe have the same length?\n",
    "if len(submission) == len(test):\n",
    "    print(\"Submission dataframe has the same length as test dataframe with shape:{}\".format(submission.shape))\n",
    "else:\n",
    "    print(\"Something is wrong!\")\n",
    "    \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Submission of predictions\n",
    "\n",
    "* submission file is saved as kernel output\n",
    "* based on the submission file the competiton F1-score is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission File as Output\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16a7b0f1d6f742c882aad05623091c4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f728f801c744ab595ebf72752b5ced5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "363d600149ac4c968a11021436879bd8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a79e0ad1040477bab16ff71753a29f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_45961449249c491591ec9cdedbb66734",
       "placeholder": "​",
       "style": "IPY_MODEL_40549984a90747adbee35000b8038f4d",
       "value": "100% 1306122/1306122 [03:33&lt;00:00, 6118.05it/s]"
      }
     },
     "40549984a90747adbee35000b8038f4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "45961449249c491591ec9cdedbb66734": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b7d0a559b3049c1b6428add65f2e527": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c4a51bdd8ea949429502e4d6673c952a",
        "IPY_MODEL_3a79e0ad1040477bab16ff71753a29f6"
       ],
       "layout": "IPY_MODEL_c935cd1be9a64ad1b0b34bcbba50d95e"
      }
     },
     "58aa8c9e0b1949309b9eb474eedab1f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_363d600149ac4c968a11021436879bd8",
       "placeholder": "​",
       "style": "IPY_MODEL_eb74fbd46e534438af6f51757d0822d3",
       "value": "0/|/| 0/? [00:00&lt;?, ?it/s]"
      }
     },
     "714a4965c0154db3bb6f4beb125ae739": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "85c932b4570f4a2ea7af8b123d0e9c69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bba3a80bfaf444d7b5abd28ad60b3460",
        "IPY_MODEL_58aa8c9e0b1949309b9eb474eedab1f4"
       ],
       "layout": "IPY_MODEL_1f728f801c744ab595ebf72752b5ced5"
      }
     },
     "bba3a80bfaf444d7b5abd28ad60b3460": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cae1b9b403054b14924940ca65a3a969",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_714a4965c0154db3bb6f4beb125ae739",
       "value": 1
      }
     },
     "c4a51bdd8ea949429502e4d6673c952a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_16a7b0f1d6f742c882aad05623091c4e",
       "max": 1306122,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ea5b3d6bbaee467a9600adbbf170b745",
       "value": 1306122
      }
     },
     "c935cd1be9a64ad1b0b34bcbba50d95e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cae1b9b403054b14924940ca65a3a969": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea5b3d6bbaee467a9600adbbf170b745": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eb74fbd46e534438af6f51757d0822d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
