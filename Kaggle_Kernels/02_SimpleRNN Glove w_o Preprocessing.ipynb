{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Data understanding\n\n* target of competition is to build a binary text classification model\n* CRISP-DM is selected as procedure model\n* Generel assumption: Information contained in the trainset is sufficient to predict the target\n\n* Insights already were optained by exploring the dataset - resulted in the following assumptions and decisions:\n*  the training dataset has a highly unqueal class dictribution. Only about 6.4% of all questions are labled as insincere: EDA: https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc\n* Consequences of this fact below"},{"metadata":{},"cell_type":"markdown","source":"#### Import libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# General\nimport pandas as pd\nimport numpy as np\nimport os\n\n# Preprocessing\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# Modeling\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense\n\n# Training\nfrom sklearn.model_selection import StratifiedKFold\n  # splits train-set into into train and validation folds\n    \n# Evaluation\nfrom keras.callbacks import Callback\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fast Run Testing\n#total_train_samples = 15000 # max is 1306122\n#total_test_samples = 2000 # max is 375806\ntotal_train_samples = 1306122 # max is 1306122\ntotal_test_samples = 375806 # max is 375806\n\n# Preprocessing\nmaxlen = 100 # max seuquence length (max 100 words of each question is used)\nmax_words = 10000 # only 10k most frequent are used to create the vocabulary\n\n# Modeling\nembedding_dim = 300 # set to 300 to be able to compare with pre-trained embeddings\n\n# Training\nkfolds = 3\nmodel_epochs = 10\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/train.csv\")\nstr_ = 'Train data loaded'\nos.system('echo '+str_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[:total_train_samples] # for Testing purposes\nnum_samples,n = df.shape\nprint(\"Shape for this run: \", num_samples, n)\n\nX = df.loc[:, 'question_text'].values\ny = df.loc[:, 'target'].values\n\n# Neural Networks are only able to perform transformations on tensors \ny = np.asarray(y) # Transformation target labels to numpy array \n\nprint('Shape data tensor:', X.shape) \nprint('Shape target tensor:', y.shape) # 1D Tensor\n\npd.set_option('display.max_colwidth', 1500) # inrease display column size\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n\n* w/o data cleaning\n* tokenisation only"},{"metadata":{},"cell_type":"markdown","source":"#### Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_tokenizer(texts):\n        tokenizer = Tokenizer(num_words=max_words)\n        tokenizer.fit_on_texts(texts) \n        sequences = tokenizer.texts_to_sequences(texts)\n        padded_seq = pad_sequences(sequences, maxlen=maxlen)  \n        word_index = tokenizer.word_index  \n        \n        return padded_seq, word_index\n\nprint(\"First sentence without tokenization: \\n\", X[0])\nprint(\"\\nFirst sentence tokenized: \\n\",  my_tokenizer(X[[0]])[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply tokenization on whole dataset\npadded_seq, word_index = my_tokenizer(X)\nprint(\"Found {} unique tokens\".format(len(word_index)))\n\n# Show first 10 words in the dictionary with their corresponding index\nfor word, index in word_index.items():\n    if index < 10:\n        print(word, index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Embeddings and Create Embedding-matrix"},{"metadata":{},"cell_type":"markdown","source":"#### Load GloVe-Embedding\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"str_ = 'Loading Embedding...'\nos.system('echo '+str_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_dict = {} # create empty embedding dictionary\n# Open glove file (vector size 300!)\nembedding_file = open('../input/embeddings/glove.840B.300d/glove.840B.300d.txt')\n\n# Fill embedding dict with word: vector(coefs) pairs\nfor line in embedding_file:\n    line_values = line.split(' ') # read in values of respective line (= vector)\n    word = line_values[0] #  # first value in line represents the word\n    coefs = np.asarray(line_values[1:], dtype='float32') \n      # # all other values in line represent the word vector\n    embeddings_dict[word] = coefs # add key(word), value(vector) pairs to dict\n\nembedding_file.close() \n\nstr_ = 'Embedding Loaded!'\nos.system('echo '+str_)\nprint('Embedding loaded')\nprint('{} word vectors within embeddings_dict.'.format(len(embeddings_dict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n#### Creation Embedding Matrix\n \n*     embeddings_dict now contains about 2.2 million words with corresponding vector representation\n*     However not all these word: vector pairs are needed\n*     A word representation from the embedding only has to be found for the most frequent 10.000 word within the text corpus (= the questions)\n*     These 10k words already are contained within word_index dict which was created earlier\n*     In the following code a embedding matrix is created for the 10k words\n* Moreover words are counted for which an embedding is not found \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 300 # (vector size 300!)\n# Creation empty matrix\nembedding_matrix = np.zeros((max_words, embedding_dim))\nknown_words_list = []\nunknown_words_list = []\n\n# Filling up matrix\nfor word, i in word_index.items(): \n        # in index data is stored: {word:index, word_index, ..}\n    if i < max_words: # only use 10k most frequent words\n        embedding_vector = embeddings_dict.get(word) \n          # get vector for word from embedding\n        if embedding_vector is not None:\n            known_words_list.append(word)\n            embedding_matrix[i] = embedding_vector\n        else:\n            unknown_words_list.append(word)\n            \n            \n              # implies that word that are not found get zero vector\n                \nprint('Embeddings_matrix created')\nprint('  Shape embedding_matrix: {}'.format(embedding_matrix.shape))\nprint('Found Embeddings for {:.2f}% of all words'.format((len(known_words_list) / max_words)*100))\nprint('Unknown Words: {:.2f}%'.format((len(unknown_words_list) / max_words)*100))\n\n# Top 10 unknown words\nunknown_words_list[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling\n\n* starting with a simple neural network\n* model is encapsulated into a function for clarity reasons and to make model easier for later submission \n* literature recommends not to use pre-trained embeddings in case of the availability of a large dataset. 1.3 million questions are available in the train-set, which should be worth a try. The Embedding Layer tries to derive optimal vectors for the input words. After training the weights of the Embedding Layer represent these vectors.\n* state-of-the-art loss function for binary classification tasks: **binary_crossentropy**\n* **optimizer rmsprop** is in most-cases a good choice according to current research literature\n* using the default learning rate of rmsprop is recommended and applied here"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_keras_model():\n    model = Sequential()\n    model.add(Embedding(input_dim = max_words, # 10k different words/integers\n                        output_dim = embedding_dim, \n                        input_length = maxlen)) # seqeuence length 100\n\n    model.add(Flatten()) # reduction 3D tensor(embedding output) to 2D tensor\n    model.add(Dense(32, activation='relu')) \n    model.add(Dense(1, activation='sigmoid')) # final -  binary classifier\n    \n    model.layers[0].set_weights([embedding_matrix]) \n    # Setting weights not trainable \n    model.layers[0].trainable = False\n    \n    model.compile(optimizer='rmsprop',\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n        \n    return model\n\nget_keras_model().summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training + Evaluation\n\n* Input for model are batches of sequences\n        * Input shape: 2D tensor(matrix): (batch_size, sequence_length).\n* each sequence has a maximum length of maxlen (here: 100)\n* Embedding Layer translates Integers of each sequence into dense vectors\n  (comp. https://keras.io/layers/embeddings/)\n      * input_length: Length of input sequence\n* embedding_matrix translates integers into into 3D Tensores of shape:\n      * Output shape: (batch_size, sequence_length, output_dim)\n\n\n* accuracy metric is not suitable is cases target classes are quite unequal distributed\n* ROC-AUC also not applicable for the same reason\n* Suitable Evaluation metrics: Precision, Recall and F1-Score as combination of both. Since these metric functions were removed in Keras 2.0, they are implemented within an own callback below. # class based on:\nhttps://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass CustomMetric(Callback):\n\n    # Creatin Instance ata the beginning of each epoch\n    def on_train_begin(self, logs={}):\n        self.val_f1s = []\n        self.val_recalls = []\n        self.val_precisions = []\n    \n    # Function called at the end of ery epoch\n    def on_epoch_end(self, epoch, logs={}):\n        # as a start simple round function as threshold\n        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n        val_target = self.validation_data[1]\n        \n        _val_f1 = f1_score(y_true = val_target, y_pred = val_predict)\n        _val_recall = recall_score(y_true = val_target,y_pred = val_predict)\n        _val_precision = precision_score(y_true = val_target,y_pred = val_predict)\n        \n        self.val_f1s.append(_val_f1)\n        self.val_recalls.append(_val_recall)\n        self.val_precisions.append(_val_precision)\n        # print(\"— val_f1: {} — val_precision: {} — val_recall {}\".format(_val_f1, _val_precision, _val_recall))\n        #print(precision_recall_fscore_support(val_target, val_predict, average = 'binary'))\n        if epoch%2 == 0:\n            print(\"  -- epoch: {}\".format(epoch))\n        return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* StratifiedKFold: training is performed \"kfold\"- time, within each fold several epochs are run."},{"metadata":{"trusted":true},"cell_type":"code","source":"# fold_list contains train and validation indices (folds) for each split\nfolds = list(StratifiedKFold(n_splits=kfolds, shuffle= True, random_state=123)\n             .split(padded_seq, y))\n\nmy_metrics = [] # list to collect metrics at the end of each split\nmy_y_val_preds = {} # dictionary to collect model predictions at the end of each split\nmy_y_val_targets = {} # dictionary of true classes at the end of each split\nbest_f1_dict = {}\nbest_threshold_dict = {}\nmy_history_dict = {}\nmy_metrics_dict = {}\nfor i, (train_indices, val_indices) in enumerate(folds):\n    \n    print('\\nSplit: {}  \\n '.format(i))\n    str_ = 'Training with Fold: '\n    os.system('echo '+ str_ + str(i)) # monitor training process in log\n    \n    X_train, X_val = padded_seq[train_indices], padded_seq[val_indices] \n    y_train, y_val = y[train_indices], y[val_indices] \n\n    model = get_keras_model() # create new model for current split\n    my_metrics = CustomMetric() # create new metrics instance\n \n    # Training process is logged in history object for visualition purposes\n    # within each split setting the model is trained several epochs (complete fit)\n    history = model.fit(X_train, y_train,\n                        epochs = model_epochs, \n                        batch_size= 32,\n                        verbose = 0, \n                        validation_data=(X_val, y_val),\n                        callbacks = [my_metrics])\n    my_history_dict[i] = history\n    my_metrics_dict[i] = my_metrics\n    \n    y_val_pred = model.predict(X_val) # prediction on \n    my_y_val_preds[i] = y_val_pred \n    my_y_val_targets[i] = y_val\n    \n    # Find best threshold for prediction\n    best_f1 = 0\n    best_threshold = 0\n    for threshold in np.arange(0.1,0.5, 0.01):\n        # calucate f1 score for allowed thresholds\n        f1_score_threshold = f1_score(y_true = y_val ,\n                                              y_pred = y_val_pred > threshold) # 0 or 1\n        if f1_score_threshold > best_f1:\n            best_f1 = f1_score_threshold\n            best_threshold = threshold\n            best_f1_dict[i] = best_f1\n            best_threshold_dict[i] = best_threshold\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nthresh_avg = 0\nthresh_sum = 0\nf1_avg = 0\nf1_sum = 0\nfor key, value in best_f1_dict.items():\n    print(\"Split: {} : Best F1 score: {:6.4f} reached with a threshold of {:6.4f}\"\n          .format(key, best_f1_dict[key], best_threshold_dict[key]))\n    thresh_sum += best_threshold_dict[key] \n    thresh_avg = thresh_sum/kfolds\n    f1_sum += best_f1_dict[key] \n    f1_avg = f1_sum/kfolds\n   \nprint(\"\")\nprint(\"Threshold for prediction: {:6.4f}\".format(thresh_avg))\nprint(\"Average F1-Score: {:5.3f}\".format(f1_avg))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation\n\n* For the evaluation of unbalanced datasets the accuracy as e.g. implemented in SKLEARN's function cross_val_score() is NOT recommended\n* A high F1 score is the target in this competition\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for hist in my_history_dict:\n    \n    print('Split: {} '.format(hist))\n    loss = my_history_dict[hist].history['loss']\n    val_loss = my_history_dict[hist].history['val_loss']\n    epochs = np.arange(1, len(loss) +1, 1) # x-axis\n\n    plt.figure()\n    plt.xticks(epochs)\n    plt.plot(epochs, loss, 'bo', label='Loss Training', color = 'black')\n    plt.plot(epochs, val_loss, 'b', label='Loss Validation')\n    plt.title('Loss function Training / Validation')\n    plt.legend()\n \n    val_f1 = my_metrics_dict[hist].val_f1s\n    plt.figure()\n    plt.xticks(epochs)\n    plt.plot(epochs, val_f1, 'b', label='F1 Validation')\n    plt.title('F1 Validation')\n    plt.legend()\n    \n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}